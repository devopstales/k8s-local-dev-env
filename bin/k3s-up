#!/bin/bash

NETWORK_TYPE=None
CILIUM_INGRESS=false


# Test nececary binaries
## yq
## helmfile

# Generate k3s config
echo "## Generating K3S Configuration"
sudo rm -rf /etc/rancher/k3s
sudo mkdir -p /etc/rancher/k3s
sudo chown $USER:$USER /etc/rancher/k3s

MASTER_IP=$(hostname -I | cut -d' ' -f1)
HOSTNAME=$(hostname)

echo "node-ip: ${MASTER_IP}
node-external-ip: ${MASTER_IP}
bind-address: ${MASTER_IP}
" >> /etc/rancher/k3s/config.yaml

# Select network
PS3='##  Select k3s network: '
options=("flannel" "cilium")
select opt in "${options[@]}"
do
    case $opt in
        "flannel")
            echo "You chose flannel"
            NETWORK_TYPE="flannel"
            break
            ;;
        "cilium")
            echo "You chose cilium"
            NETWORK_TYPE="cilium"
            echo "flannel-backend: none
disable-network-policy: true
" >> /etc/rancher/k3s/config.yaml
            break
            ;;
        *) echo "invalid option $REPLY";;
    esac
done

# Select Ingress
if [ $NETWORK_TYPE == "cilium" ]; then
  PS3='##  Select Ingress Controller: '
  options=("traefic" "nginx" "pomerium", "cilium")
  select opt in "${options[@]}"
  do
      case $opt in
          "traefic")
              echo "You chose traefic"
              INGRESS_TYPE="traefic"
              break
              ;;
          "nginx")
              echo "You chose nginx"
              INGRESS_TYPE="nginx"
              break
              ;;
          "pomerium")
              echo "You chose pomerium"
              INGRESS_TYPE="pomerium"
              break
              ;;
          "cilium")
              echo "You chose cilium"
              INGRESS_TYPE="cilium"
              CILIUM_INGRESS=true
              break
              ;;
          *) echo "invalid option $REPLY";;
      esac
  done
else
  PS3='##  Select Ingress Controller: '
  options=("traefic" "nginx" "pomerium")
  select opt in "${options[@]}"
  do
      case $opt in
          "traefic")
              echo "You chose traefic"
              INGRESS_TYPE="traefic"
              break
              ;;
          "nginx")
              echo "You chose nginx"
              INGRESS_TYPE="nginx"
              break
              ;;
          "pomerium")
              echo "You chose pomerium"
              INGRESS_TYPE="pomerium"
              break
              ;;
          *) echo "invalid option $REPLY";;
      esac
  done
fi

if [ $INGRESS_TYPE != "traefik" ]; then
  echo "disable:
  - traefik
  - servicelb
  " >> /etc/rancher/k3s/config.yaml
fi

# Get k3s if not installed
echo "##  Install K3S"
if ! [ -x "$(command -v k3s)" ]; then
  k3s-get
fi

# Start k3s
sudo systemctl start k3s
sudo systemctl disable k3s
sudo chown $USER:$USER /etc/rancher/k3s/k3s.yaml
sudo chmod 755 /var/lib/rancher/k3s/server
sudo mkdir -p /var/lib/rancher/k3s/server/manifests/custom
sudo chown $USER:$USER -R /var/lib/rancher/k3s/server/manifests/custom
export KUBECONFIG=/etc/rancher/k3s/k3s.yaml

# Generate Certificate
if [ ! -f $HOME/k8s-local-dev-env/.certs/rootCA.pem ]; then
  echo "##  Generate CA Certificate"
  k3s-certgen
fi
echo "##  Deploy CA Certificate"
kubectl -n ingress-system create secret tls ca-key-pair \
  --cert=$HOME/k8s-local-dev-env/.certs/rootCA.pem \
  --key=$HOME/k8s-local-dev-env/.certs/rootCA-key.pem \
  --dry-run=client -o yaml > /var/lib/rancher/k3s/server/manifests/custom/ca-cert.yaml

# Generate CoreDNS Config
echo "apiVersion: v1
kind: ConfigMap
data:
  Corefile: |
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
          pods insecure
          fallthrough in-addr.arpa ip6.arpa
        }
        hosts /etc/coredns/NodeHosts {
          ttl 60
          reload 15s
          fallthrough
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
    import /etc/coredns/custom/*.server
  NodeHosts: |
    ${MASTER_IP} ${HOSTNAME}
    ${MASTER_IP} registry.k3s.intra
" > /var/lib/rancher/k3s/server/manifests/custom/000-coredns-cpnfig.yaml

# Copy manifests
echo "Copying config to autodeploy directory"
cp -r $HOME/k8s-local-dev-env/k3s/manifests/* /var/lib/rancher/k3s/server/manifests/custom

# create ingress
if [ $INGRESS_TYPE == "traefik" ]; then
  echo "## Copy traefik dashboard ingress"
  cp $HOME/k8s-local-dev-env/k3s/optional/031-traefik-dashboard-ingress.yaml /var/lib/rancher/k3s/server/manifests/custom
elif [ $INGRESS_TYPE == "nginx" ]; then
  echo "## Copy nginx manifest"
  cp $HOME/k8s-local-dev-env/k3s/optional/030-nginx-ingress-controller.yaml /var/lib/rancher/k3s/server/manifests/custom
elif [ $INGRESS_TYPE == "pomerium" ]; then
  echo "## Copy pomerium manifest"
  cp $HOME/k8s-local-dev-env/k3s/optional/030-pomerium-ingress-controller.yaml /var/lib/rancher/k3s/server/manifests/custom
fi

# Cilium config
if [ $NETWORK_TYPE == "cilium" ]; then
    # Enable monitoring
    read -n 1 -p "Would you want to enable Monitoring? (y/N): " monitoring;
    case $monitoring in
        n|N)
            echo -e "\nno"
            MONITORING=false
            ;;
        y|Y)
            echo -e "\nyes"
            MONITORING=true
            ;;
        *)
            echo "No"
            MONITORING=false
            ;;
    esac
    # Select Apigateway
    read -n 1 -p "Would you want to enable ApiGateway? (y/N): " gateway;
    case $gateway in
        n|N)
            echo -e "\nno"
            GATEWAY_API=false
            ;;
        y|Y)
            echo -e "\nyes"
            GATEWAY_API=true
            ;;
        *)
            echo "No"
            GATEWAY_API=false
            ;;
    esac
    # Apply monitoring
    if $MONITORING; then
      helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
      helm template kube-prometheus prometheus-community/kube-prometheus-stack --include-crds \
        | yq 'select(.kind == "CustomResourceDefinition") * {"metadata": {"annotations": {"meta.helm.sh/release-name": "kube-prometheus", "meta.helm.sh/release-namespace": "monitoring-system"}}}' \
        | kubectl create -f -
      kubectl create ns monitoring-system
    fi
    # Apply Apigateway
    if $GATEWAY_API; then
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v0.7.0/config/crd/experimental/gateway.networking.k8s.io_gatewayclasses.yaml
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v0.7.0/config/crd/experimental/gateway.networking.k8s.io_gateways.yaml
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v0.7.0/config/crd/experimental/gateway.networking.k8s.io_httproutes.yaml
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v0.7.0/config/crd/experimental/gateway.networking.k8s.io_tlsroutes.yaml
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v0.7.0/config/crd/experimental/gateway.networking.k8s.io_referencegrants.yaml
        kubectl get crd | awk '{if ($1 ~ "NAME|networking.k8s.io") print $0}'
    fi
    # Generate Cilium Config
    echo "Generating Cilium helm values"
    echo "kubeProxyReplacement: "strict"
k8sServiceHost: ${MASTER_IP}
k8sServicePort: 6443
rollOutCiliumPods: true
ipv4:
  enabled: true
ipv6:
  enabled: true
gatewayAPI:
  enabled: ${GATEWAY_API}
ingressController:
  enabled: ${CILIUM_INGRESS}
  loadbalancerMode: shared
loadBalancer:
  l7:
    backend: envoy
hubble:
  metrics:
    serviceMonitor:
      enabled: ${MONITORING}
    dashboards:
      enabled: ${MONITORING}
      namespace: monitoring-system
      annotations:
        grafana_folder: Hubble
    enableOpenMetrics: false
    enabled:
    - dns:query;ignoreAAAA
    - drop
    - tcp
    - flow
    - port-distribution
    - icmp
    - http
  ui:
    enabled: true
    replicas: 1
    ingress:
      enabled: true
      hosts:
        - hubble.k3s.intra
      annotations:
        kubernetes.io/ingress.class: ${INGRESS_TYPE}
        cert-manager.io/cluster-issuer: ca-issuer
        ingress.pomerium.io/allow_any_authenticated_user: "true"
      tls:
      - secretName: hubble-ingress-tls
        hosts:
        - hubble.k3s.intra
    backend:
      resources:
        limits:
          cpu: 60m
          memory: 300Mi
        requests:
          cpu: 20m
          memory: 64Mi
    frontend:
      server:
        ipv6:
          enabled: false
      resources:
        limits:
          cpu: 1000m
          memory: 1024M
        requests:
          cpu: 100m
          memory: 64Mi
    proxy:
      resources:
        limits:
          cpu: 1000m
          memory: 1024M
        requests:
          cpu: 100m
          memory: 64Mi
  relay:
    enabled: true
    resources:
      limits:
        cpu: 100m
        memory: 500Mi
operator:
  replicas: 1
  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 128Mi
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: ${MONITORING}
ipam:
  mode: "cluster-pool"
  operator:
    clusterPoolIPv4PodCIDRList: "10.43.0.0/16"
    clusterPoolIPv4MaskSize: 24
    clusterPoolIPv6PodCIDRList: "fd00::/104"
    clusterPoolIPv6MaskSize: 120
resources:
  limits:
    cpu: 4000m
    memory: 4Gi
  requests:
    cpu: 100m
    memory: 512Mi
prometheus:
  enabled: true
  serviceMonitor:
    enabled: ${MONITORING}
" > $HOME/k8s-local-dev-env/k3s/helmfile/000-cilium-values.yaml
    # Install Cilium
    echo "Installing cilium"
    helmfile apply -f $HOME/k8s-local-dev-env/k3s/helmfile/000-cilium.yaml 2>/dev/null
fi

# Install local zfs storage
read -n 1 -p "Would you want to install openebs zfs-localpv? (y/N): " openebs;
case $openebs in
    n|N)
        echo -e "\nno"
        ;;
    y|Y)
        echo -e "\nyes"
        kubectl apply -f $HOME/k8s-local-dev-env/k3s/optional/zfs-pv/001-zfs-operator.yaml
        kubectl apply -f $HOME/k8s-local-dev-env/k3s/optional/zfs-pv/002-zfs-sc.yaml
        kubectl apply -f $HOME/k8s-local-dev-env/k3s/optional/zfs-pv/003-zfs-ssc.yaml
        ;;
    *)
        echo "No"
        CILIUM_INGRESS=false
        ;;
esac

# TODO: if tilt
# Annotate nodes with registry info for Tilt to auto-detect
#echo "Waiting for node(s) + annotating with registry info..."
#DONE=""
#timeout=$(($(date +%s) + 30))
#until [[ $(date +%s) -gt $timeout ]]; do
#  nodes=$(kubectl get nodes -o go-template --template='{{range .items}}{{printf "%s\n" .metadata.name}}{{end}}')
#  if [ ! -z $nodes ]; then
#    for node in $nodes; do
#      kubectl annotate node "${node}" \
#              tilt.dev/registry=localhost:${reg_port} \
#              tilt.dev/registry-from-cluster=${reg_name}:${reg_port}
#    done
#    DONE=true
#    break
#  fi
#  sleep 0.2
#done
#
#if [ -z "$DONE" ]; then
#  echo "Timed out waiting for node(s) to be up"
#  exit 1
#fi

# https://github.com/isovalent/cilium-grafana-observability-demo
# https://medium.com/@norlin.t/initial-impressions-of-the-cilium-grafana-observability-demo-dd81d73df96e
# https://medium.com/@norlin.t/cilium-with-ingress-opentelemetry-and-l7-policies-44522e349abe
